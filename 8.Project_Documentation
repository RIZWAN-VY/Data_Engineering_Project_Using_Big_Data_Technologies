 PROJECT DOCUMENTATION 
 
 Steps :
 
* Load a csv file of ur choice preferable from kaggle to hadoop :-

downloaded data from kaggle
data = Sales_Data.csv

-----------------

* upload data to hadoop HDFS:-

commands :
hadoop fs -mkdir /Data_Engineering_Project_HDFS
hadoop fs -put /home/rizwan/Downloads/Sales_Data.csv /Data_Engineering_Project_HDFS
hadoop fs -cat /Data_Engineering_Project_HDFS/Sales_Data.csv

-----------------

* create a managed table in Hive and load data from HDFS to hive :-
   
hive> CREATE TABLE sales_data_table (
      dte STRING,
      product STRING,
      category STRING,
      sales_rep STRING,
      city STRING,
      no_of_units INT,
      price DOUBLE,
      amount DOUBLE
      )
      ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
      TBLPROPERTIES ('skip.header.line.count'='1');

hive> LOAD DATA INPATH '/Data_Engineering_Project_HDFS/Sales_Data.csv' INTO TABLE sales_data;

hive> SELECT * FROM sales_data_table;

-----------------

* Connected Hive and Spark :-

file = Sales_Data_Analysis.ipynb 

spark = SparkSession.builder.appName("Sales_Data_Analytics") \
        .config("spark.sql.warehouse.dir", "/user/hive/warehouse") \
        .enableHiveSupport().getOrCreate()

# appName = Provide a name for your Spark application
# config  = Set Hive warehouse directory
# enableHiveSupport = Enable Hive support


* Analysed the data using Apache Spark SQL and find insight like
   *, Sales Statistics
   *, Top selling Product
   *, Top selling product Category
   *, Best performing sales representitive
   *, Sales by city
   
   saved these insight in the file "Sales_Data_Insight"
   
-----------------

* uploaded the insight into HDFS

hadoop fs -put /home/rizwan/Desktop/Sales_Data_Insight /Sales_Data_Analysis_and_Automation
  
-----------------

Automated the entire process using Apache Airflow

file = Sales_Data_Analysis_Automation_Airflow.py

-----------------

visualised the data in powerbi
created an interactive dashboard in power bi
