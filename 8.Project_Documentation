 PROJECT DOCUMENTATION 
 
 Steps :
 	1.Creating a folder in Hadoop HDFS

	2.Uploading the Dataset to the created folder in Hadoop HDFS

	3.Creating a table in Hive which is compactable with the Dataset
	4.Extracting the data from HDFS to the table created in Hive
	5.Connecting Hive and Spark and doing analysis using Spark SQL
             Sales Statistics
             Top Selling Product
             Top Product Category
             Top Performing Sales Representative
             Sales by City
	6.Uploading the analysed data back to HDFS
	7.Automate the entire workflow using Apache Airflow
	

* Load a csv file of ur choice preferable from kaggle to hadoop :-

downloaded data from kaggle

-----------------
data = Sales_Data.csv

* upload data to hadoop HDFS:-

commands :
hadoop fs -mkdir /Data_Engineering_Project_HDFS
hadoop fs -put /home/rizwan/Downloads/Sales_Data.csv /Data_Engineering_Project_HDFS
hadoop fs -cat /Data_Engineering_Project_HDFS/Sales_Data.csv

-----------------

* create a managed table in Hive and load data from HDFS to hive :-
   
hive> CREATE TABLE sales_data_table (
      dte STRING,
      product STRING,
      category STRING,
      sales_rep STRING,
      city STRING,
      no_of_units INT,
      price DOUBLE,
      amount DOUBLE
      )
      ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
      TBLPROPERTIES ('skip.header.line.count'='1');

hive> LOAD DATA INPATH '/Data_Engineering_Project_HDFS/Sales_Data.csv' INTO TABLE sales_data;

hive> SELECT * FROM sales_data_table;

-----------------

* Connected Hive and Spark :-

file = Sales_Data_Analysis.ipynb 

spark = SparkSession.builder.appName("Sales_Data_Analytics") \
        .config("spark.sql.warehouse.dir", "/user/hive/warehouse") \
        .enableHiveSupport().getOrCreate()

# appName = Provide a name for your Spark application
# config  = Set Hive warehouse directory
# enableHiveSupport = Enable Hive support


* Analysed the data using Apache Spark SQL and find insight like
   *, Sales Statistics
   *, Top selling Product
   *, Top selling product Category
   *, Best performing sales representitive
   *, Sales by city
   
   saved these insight in the file "Sales_Data_Insight"
   
-----------------

* uploaded the insight into HDFS

hadoop fs -put /home/rizwan/Desktop/Sales_Data_Insight /Sales_Data_Analysis_and_Automation
  
-----------------

Automated the entire process using Apache Airflow

file = Sales_Data_Analysis_Automation_Airflow.py

-----------------

visualised the data in powerbi
created an interactive dashboard in power bi
