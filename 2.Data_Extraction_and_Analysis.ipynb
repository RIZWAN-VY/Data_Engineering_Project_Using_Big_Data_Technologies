{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA EXTRACTION FROM APACHE HIVE AND \n",
    "# ANALYSIS USING APACHE SPARK- SPARK SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES:\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_timestamp,month,expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting Spark and Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/10/06 14:31:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Data_Extraction_and_Analysis\") \\\n",
    "        .config(\"spark.sql.warehouse.dir\", \"/user/hive/warehouse\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# appName = Provide a name for your Spark application\n",
    "# config  = Set Hive warehouse directory\n",
    "# enableHiveSupport = Enable Hive support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Data from Apache Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.sql(\"SELECT * FROM sales_database.sales_data_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+\n",
      "|summary|       no_of_units|            price|            amount|\n",
      "+-------+------------------+-----------------+------------------+\n",
      "|  count|              1560|             1560|              1560|\n",
      "|   mean|12.547435897435898|972.6666666666666| 5426.029487179487|\n",
      "| stddev| 15.46123231746398|671.4694648673942|2686.7067453959307|\n",
      "|    min|                 1|             75.0|             630.0|\n",
      "|    max|                90|           2001.0|           12006.0|\n",
      "+-------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "statistics = data.describe([\"no_of_units\", \"price\", \"amount\"])\n",
    "statistics .show()\n",
    "\n",
    "# Save the analyzed data \n",
    "statistics.write.csv(\"/home/rizwan/Data_Engineering_Project/Analysed_Data/Sales_Statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count : There are 1560 data points in each of the columns (no_of_units, price, and amount).\n",
    "\n",
    "Mean  : The average number of units sold is approximately 12.55, the average price is \n",
    "        approximately 972.67,and the average amount is approximately 5426.03.\n",
    "\n",
    "Standard Deviation : The standard deviation for the number of units sold is approximately 15.46,  \n",
    "                     for the price  is approximately 671.47, and for the amount is approximately 2686.71.\n",
    "\n",
    "Minimum : The minimum number of units sold is 1, the minimum price is 75.0, and the minimum amount is 630.0.\n",
    "    \n",
    "Maximum : The maximum number of units sold is 90, the maximum price is 2001.0, and the maximum amount is 12006.0.\n",
    "\n",
    "These statistics provide a basic overview of the distribution and central tendencies of your numeric columns.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROUPING AND AGGREGATION :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Sales by Product  [ Top Selling Product ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+-----------+-------------+\n",
      "|          product|total_units|total_price|product_sales|\n",
      "+-----------------+-----------+-----------+-------------+\n",
      "|      Dell XPS 13|       1181|   520260.0|    2363181.0|\n",
      "|    iPhone 11 Pro|       1057|   409500.0|    1664775.0|\n",
      "|    OnePlus 8 Pro|       2056|   205400.0|    1624240.0|\n",
      "|     HP Envy x360|       1058|   280800.0|    1142640.0|\n",
      "|     OnePlus Buds|      11709|    19500.0|     878175.0|\n",
      "|Apple AirPods Pro|       2513|    81900.0|     791595.0|\n",
      "+-----------------+-----------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_sales = spark.sql(\"SELECT product,SUM(no_of_units) AS total_units,\\\n",
    "                           SUM(price) AS total_price,SUM(amount) AS product_sales \\\n",
    "                           FROM sales_database.sales_data_table \\\n",
    "                           GROUP BY product ORDER BY product_sales DESC\")\n",
    "product_sales.show()\n",
    "\n",
    "# Save the analyzed data \n",
    "product_sales.write.csv(\"/home/rizwan/Data_Engineering_Project/Analysed_Data/product_sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Dell XPS 13\" is the top-selling product with a total sales amount of 2,363,181.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Sales by Product Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "| Category|total_sales|\n",
      "+---------+-----------+\n",
      "|   Laptop|  3505821.0|\n",
      "|    Phone|  3289015.0|\n",
      "|Headphone|  1669770.0|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_sales = spark.sql(\"SELECT Category,SUM(amount) AS total_sales \\\n",
    "                            FROM sales_database.sales_data_table \\\n",
    "                            GROUP BY Category ORDER BY total_sales DESC\")\n",
    "category_sales.show()\n",
    "\n",
    "# Save the analyzed data \n",
    "category_sales.write.csv(\"/home/rizwan/Data_Engineering_Project/Analysed_Data/category_sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category that recorded the highest total sales is \"Laptop\" with a sales figure of 3,505,821.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Sales by Sales Representative   [ Top Performing Sales Representative ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+\n",
      "|sales_rep|sale_rep_totalsales|\n",
      "+---------+-------------------+\n",
      "|     Amar|          1141490.0|\n",
      "|     Kate|          1022509.0|\n",
      "|     Tara|           995525.0|\n",
      "|    Aryan|           870300.0|\n",
      "|    Leila|           846425.0|\n",
      "|     Asif|           804762.0|\n",
      "|    Giana|           742570.0|\n",
      "|    Krish|           725580.0|\n",
      "|    Bruce|           717555.0|\n",
      "|    Laxmi|           597890.0|\n",
      "+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sale_rep_totalsales = spark.sql(\"SELECT sales_rep, SUM(amount) AS sale_rep_totalsales \\\n",
    "                                 FROM sales_database.sales_data_table \\\n",
    "                                 GROUP BY sales_rep ORDER BY sale_rep_totalsales DESC\")\n",
    "sale_rep_totalsales.show()\n",
    "\n",
    "# Save the analyzed data \n",
    "sale_rep_totalsales.write.csv(\"/home/rizwan/Data_Engineering_Project/Analysed_Data/sale_rep_totalsales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are sorted in descending order of the \"sale_rep_totalsales\" column, showing the sales representatives with the highest total sales at the top.  \n",
    "\"Amar\" is the top-performing sales representative with a total sales amount of 1,141,490.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Sales by city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|     city|totalsales_by_city|\n",
      "+---------+------------------+\n",
      "|   Mumbai|         1748089.0|\n",
      "|Hyderabad|         1739380.0|\n",
      "|    Delhi|         1716725.0|\n",
      "|Bangalore|         1713080.0|\n",
      "|   Cochin|         1547332.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_by_city = spark.sql(\"SELECT city, SUM(amount) AS totalsales_by_city \\\n",
    "                           FROM sales_database.sales_data_table \\\n",
    "                           GROUP BY city ORDER BY totalsales_by_city DESC\")\n",
    "sales_by_city.show()\n",
    "\n",
    "# Save the analyzed data \n",
    "sales_by_city.write.csv(\"/home/rizwan/Data_Engineering_Project/Analysed_Data/sales_by_city\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Mumbai\" is the city with the highest total sales, with a total sales amount of 1,748,089.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monthly Sales Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = data.withColumn('dte', to_timestamp(data['dte'], 'dd-MM-yyyy'))\n",
    "# df.printSchema()\n",
    "\n",
    "df = df.withColumn('month', month(df['dte']))  # Extract month\n",
    "# df.show()\n",
    "\n",
    "# Create a new column using 'expr' and 'if-elif-else' conditions\n",
    "df = df.withColumn(\n",
    "    'month_name',\n",
    "    expr(\n",
    "        \"CASE \"\n",
    "        \"WHEN month = 1 THEN 'January' \"\n",
    "        \"WHEN month = 2 THEN 'February' \"\n",
    "        \"WHEN month = 3 THEN 'March' \"\n",
    "        \"WHEN month = 4 THEN 'April' \"\n",
    "        \"WHEN month = 5 THEN 'May' \"\n",
    "        \"WHEN month = 6 THEN 'June' \"\n",
    "        \"WHEN month = 7 THEN 'July' \"\n",
    "        \"WHEN month = 8 THEN 'August' \"\n",
    "        \"WHEN month = 9 THEN 'September' \"\n",
    "        \"WHEN month = 10 THEN 'October' \"\n",
    "        \"WHEN month = 11 THEN 'November' \"\n",
    "        \"WHEN month = 12 THEN 'December' \"\n",
    "        \"ELSE NULL END\"\n",
    "    )\n",
    ")\n",
    "# df.show()\n",
    "\n",
    "# Save the analyzed data \n",
    "df.write.csv(\"/home/rizwan/Data_Engineering_Project/Analysed_Data/Processed_Sales_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----------+\n",
      "|month|month_name|sum(amount)|\n",
      "+-----+----------+-----------+\n",
      "|   12|  December|   847373.0|\n",
      "|    7|      July|   833267.0|\n",
      "|   10|   October|   832298.0|\n",
      "|    4|     April|   805897.0|\n",
      "|    5|       May|   679908.0|\n",
      "|   11|  November|   660067.0|\n",
      "|    6|      June|   655666.0|\n",
      "|    2|  February|   648716.0|\n",
      "|    1|   January|   640162.0|\n",
      "|    9| September|   632641.0|\n",
      "|    8|    August|   618466.0|\n",
      "|    3|     March|   610145.0|\n",
      "+-----+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by month and calculate total sales for each month\n",
    "monthly_sales = df.groupBy('month','month_name').agg({'amount':'sum'})\n",
    "# monthly_sales = monthly_sales.sort(monthly_sales['month'])\n",
    "# monthly_sales.show()\n",
    "\n",
    "# Sort by total sales in descending order to find the month with the highest sales\n",
    "monthly_sales = monthly_sales.sort(monthly_sales['sum(amount)'].desc())\n",
    "monthly_sales.show()\n",
    "\n",
    "# Save the analyzed data in ORC format\n",
    "monthly_sales.write.csv(\"/home/rizwan/Data_Engineering_Project/Analysed_Data/monthly_sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"December\" is the month with highest total sales with 847,373.\n",
    "\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
