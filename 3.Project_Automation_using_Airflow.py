'''
 AUTOMATING THE ENTIRE WORKFLOW USING APACHE AIRFLOW
=====================================================

Steps :
    1.Creating a folder in Hadoop HDFS
    2.Uploading the Dataset to the created folder in HDFS
    3.Creating a table in Hive which is compactable with the Dataset
    4.Extracting the data from HDFS to the table created in Hive
    5.Connecting Hive and Spark and doing analysis using Spark SQL
        Sales Statistics
        Top Selling Product
        Top Product Category
        Top Performing Sales Representative
        Sales by City
    6.Uploading the analysed data back to HDFS
'''